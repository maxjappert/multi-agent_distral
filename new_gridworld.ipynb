{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c9eb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EMPTY, WALL, TARGET1, TARGET2, AGENT1, AGENT2 = range(6)\n",
    "ACTIONS = [0, 1, 2, 3, 4]  # NOOP, UP, DOWN, LEFT, RIGHT\n",
    "\n",
    "COLORS = {\n",
    "    EMPTY: [1.0, 1.0, 1.0],\n",
    "    WALL: [0.0, 0.0, 0.0],\n",
    "    TARGET1: [0.0, 0.5, 0.0],\n",
    "    TARGET2: [0.5, 0.0, 0.0],\n",
    "    AGENT1: [0.5, 1.0, 0.5],\n",
    "    AGENT2: [1.0, 0.5, 0.5],\n",
    "}\n",
    "\n",
    "ACTION_EFFECTS = {\n",
    "    0: (0, 0),\n",
    "    1: (-1, 0),\n",
    "    2: (1, 0),\n",
    "    3: (0, -1),\n",
    "    4: (0, 1),\n",
    "}\n",
    "\n",
    "class GridworldEnv:\n",
    "    def __init__(self, grid_map):\n",
    "        self.grid_map = np.array(grid_map, dtype=int)\n",
    "        self.agents_start_coords, self.agents_target_coords = self._find_agents_and_targets()\n",
    "        self.current_agents_coords = np.copy(self.agents_start_coords)\n",
    "        self.move_completed = [False, False]\n",
    "        self.current_game_state = self._get_state()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_agents_coords = np.copy(self.agents_start_coords)\n",
    "        self.move_completed = [False, False]\n",
    "        self.current_game_state = self._get_state()\n",
    "        return self.current_game_state\n",
    "\n",
    "    def step(self, actions):\n",
    "        rewards = [0.0, 0.0]\n",
    "        new_agent_coords = np.copy(self.current_agents_coords)\n",
    "\n",
    "        for agent_idx, action in enumerate(actions):\n",
    "            if self.move_completed[agent_idx]:\n",
    "                continue\n",
    "\n",
    "            dy, dx = ACTION_EFFECTS[action]\n",
    "            y, x = self.current_agents_coords[agent_idx]\n",
    "            new_y, new_x = y + dy, x + dx\n",
    "\n",
    "            if not self._move_legal(new_y, new_x, agent_idx):\n",
    "                rewards[agent_idx] = -0.1\n",
    "                continue\n",
    "\n",
    "            if self._target_reached(agent_idx, new_y, new_x):\n",
    "                self.move_completed[agent_idx] = True\n",
    "                rewards[agent_idx] = 100.0\n",
    "            else:\n",
    "                rewards[agent_idx] = -0.1\n",
    "\n",
    "            new_agent_coords[agent_idx] = [new_y, new_x]\n",
    "\n",
    "        self.current_agents_coords = new_agent_coords\n",
    "        self.current_game_state = self._get_state()\n",
    "        done = all(self.move_completed)\n",
    "\n",
    "        return self.current_game_state, rewards, done\n",
    "\n",
    "    def render(self):\n",
    "        img = self._gridmap_to_image()\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    def _within_bounds(self, y, x):\n",
    "        return 0 <= y < self.grid_map.shape[0] and 0 <= x < self.grid_map.shape[1]\n",
    "\n",
    "    def _move_legal(self, y, x, agent_idx):\n",
    "        if not self._within_bounds(y, x) or self.grid_map[y, x] == WALL:\n",
    "            return False\n",
    "\n",
    "        if agent_idx == 0 and self.grid_map[y, x] == AGENT2:\n",
    "            return False\n",
    "\n",
    "        if agent_idx == 1 and self.grid_map[y, x] == AGENT1:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _target_reached(self, agent_idx, y, x):\n",
    "        target = TARGET1 if agent_idx == 0 else TARGET2\n",
    "        return self.grid_map[y, x] == target\n",
    "\n",
    "    def _find_agents_and_targets(self):\n",
    "        start_coords = []\n",
    "        target_coords = []\n",
    "        for agent, target in [(AGENT1, TARGET1), (AGENT2, TARGET2)]:\n",
    "            sy, sx = np.where(self.grid_map == agent)\n",
    "            ty, tx = np.where(self.grid_map == target)\n",
    "            start_coords.append([sy[0], sx[0]])\n",
    "            target_coords.append([ty[0], tx[0]])\n",
    "        return np.array(start_coords), np.array(target_coords)\n",
    "\n",
    "    def _get_state(self):\n",
    "        return np.concatenate([self.current_agents_coords.flatten(), self.move_completed])\n",
    "\n",
    "    def _gridmap_to_image(self):\n",
    "        img = np.zeros((*self.grid_map.shape, 3))\n",
    "        for i in range(self.grid_map.shape[0]):\n",
    "            for j in range(self.grid_map.shape[1]):\n",
    "                img[i, j] = COLORS[self.grid_map[i, j]]\n",
    "\n",
    "        for idx, (y, x) in enumerate(self.current_agents_coords):\n",
    "            img[y, x] = COLORS[idx]\n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f153bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of the environment\n",
    "grid_map = [\n",
    "    [EMPTY, EMPTY, EMPTY, WALL, EMPTY, EMPTY, EMPTY],\n",
    "    [EMPTY, AGENT1, EMPTY, WALL, EMPTY, AGENT2, EMPTY],\n",
    "    [EMPTY, EMPTY, EMPTY, WALL, EMPTY, EMPTY, EMPTY],\n",
    "    [WALL, WALL, WALL, WALL, WALL, WALL, WALL],\n",
    "    [EMPTY, EMPTY, EMPTY, WALL, EMPTY, EMPTY, EMPTY],\n",
    "    [EMPTY, EMPTY, EMPTY, WALL, EMPTY, EMPTY, EMPTY],\n",
    "    [EMPTY, TARGET1, EMPTY, WALL, EMPTY, TARGET2, EMPTY],\n",
    "]\n",
    "env = GridworldEnv(grid_map)\n",
    "\n",
    "# Reset the environment and get the initial state\n",
    "state = env.reset()\n",
    "\n",
    "# Render the initial state\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf23ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EMPTY, WALL, TARGET1, TARGET2, AGENT1, AGENT2 = range(6)\n",
    "ACTIONS = [0, 1, 2, 3, 4]  # NOOP, UP, DOWN, LEFT, RIGHT\n",
    "\n",
    "COLORS = {\n",
    "    EMPTY: [1.0, 1.0, 1.0],  # White\n",
    "    WALL: [0.0, 0.0, 0.0],  # Black\n",
    "    TARGET1: [0.0, 0.5, 0.0],  # Dark Green\n",
    "    TARGET2: [0.5, 0.0, 0.0],  # Dark Red\n",
    "    AGENT1: [0.5, 1.0, 0.5],  # Light Green\n",
    "    AGENT2: [1.0, 0.5, 0.5],  # Light Red\n",
    "}\n",
    "\n",
    "ACTION_EFFECTS = {\n",
    "    0: (0, 0),\n",
    "    1: (-1, 0),\n",
    "    2: (1, 0),\n",
    "    3: (0, -1),\n",
    "    4: (0, 1),\n",
    "}\n",
    "\n",
    "class GridworldEnv:\n",
    "    def __init__(self, grid_map):\n",
    "        self.grid_map = np.array(grid_map, dtype=int)\n",
    "        self.agents_start_coords, self.agents_target_coords = self._find_agents_and_targets()\n",
    "        self.current_agents_coords = np.copy(self.agents_start_coords)\n",
    "        self.move_completed = [False, False]\n",
    "        self.current_game_state = self._get_state()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_agents_coords = np.copy(self.agents_start_coords)\n",
    "        self.move_completed = [False, False]\n",
    "        self.current_game_state = self._get_state()\n",
    "        return self.current_game_state\n",
    "\n",
    "    def step(self, actions):\n",
    "        rewards = [0.0, 0.0]\n",
    "        new_agent_coords = np.copy(self.current_agents_coords)\n",
    "\n",
    "        for agent_idx, action in enumerate(actions):\n",
    "            if self.move_completed[agent_idx]:\n",
    "                continue\n",
    "\n",
    "            dy, dx = ACTION_EFFECTS[action]\n",
    "            y, x = self.current_agents_coords[agent_idx]\n",
    "            new_y, new_x = y + dy, x + dx\n",
    "\n",
    "            if not self._move_legal(new_y, new_x, agent_idx):\n",
    "                rewards[agent_idx] = -0.1\n",
    "                continue\n",
    "\n",
    "            if self._target_reached(agent_idx, new_y, new_x):\n",
    "                self.move_completed[agent_idx] = True\n",
    "                rewards[agent_idx] = 100.0\n",
    "            else:\n",
    "                rewards[agent_idx] = -0.1\n",
    "\n",
    "            new_agent_coords[agent_idx] = [new_y, new_x]\n",
    "\n",
    "        self.current_agents_coords = new_agent_coords\n",
    "        self.current_game_state = self._get_state()\n",
    "        done = all(self.move_completed)\n",
    "\n",
    "        return self.current_game_state, rewards, done\n",
    "\n",
    "    def render(self):\n",
    "        img = self._gridmap_to_image()\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    def _within_bounds(self, y, x):\n",
    "        return 0 <= y < self.grid_map.shape[0] and 0 <= x < self.grid_map.shape[1]\n",
    "\n",
    "    def _move_legal(self, y, x, agent_idx):\n",
    "        if not self._within_bounds(y, x) or self.grid_map[y, x] == WALL:\n",
    "            return False\n",
    "\n",
    "        if agent_idx == 0 and self.grid_map[y, x] == AGENT2:\n",
    "            return False\n",
    "\n",
    "        if agent_idx == 1 and self.grid_map[y, x] == AGENT1:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _target_reached(self, agent_idx, y, x):\n",
    "        target = TARGET1 if agent_idx == 0 else TARGET2\n",
    "        return self.grid_map[y, x] == target\n",
    "\n",
    "    def _find_agents_and_targets(self):\n",
    "        start_coords = []\n",
    "        target_coords = []\n",
    "        for agent, target in [(AGENT1, TARGET1), (AGENT2, TARGET2)]:\n",
    "            sy, sx = np.where(self.grid_map == agent)\n",
    "            ty, tx = np.where(self.grid_map == target)\n",
    "            start_coords.append([sy[0], sx[0]])\n",
    "            target_coords.append([ty[0], tx[0]])\n",
    "        return np.array(start_coords), np.array(target_coords)\n",
    "\n",
    "    def _get_state(self):\n",
    "        return np.concatenate([self.current_agents_coords.flatten(), self.move_completed])\n",
    "\n",
    "    def _gridmap_to_image(self):\n",
    "        img = np.zeros((*self.grid_map.shape, 3))\n",
    "        for i in range(self.grid_map.shape[0]):\n",
    "            for j in range(self.grid_map.shape[1]):\n",
    "                if self.grid_map[i, j] == EMPTY:\n",
    "                    img[i, j] = COLORS[EMPTY]  # Change EMPTY to WALL color (black)\n",
    "                else:\n",
    "                    img[i, j] = COLORS[self.grid_map[i, j]]\n",
    "\n",
    "        for idx, (y, x) in enumerate(self.current_agents_coords):\n",
    "            img[y, x] = COLORS[idx]\n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba8b81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANoAAAD4CAYAAACKefjmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAJ5klEQVR4nO3dTYhdhRnG8efpRGn9qC76QUhCTUGyaDeRYBGLtIolxaAuulBooVLIyhApRawru+i22JUQUq1gqpSoICJaoVIttDYfpmgSlTTYZlJtFLF+bIL16WJOIJrM3DOZc95z58z/B9LMzZ3Le8f+Pefeufe9TiIA/frc0AMAKwGhAQUIDShAaEABQgMKrOrjRm3zVCZWpCQ+2+Uc0YAChAYUIDSgAKEBBQgNKEBoQAFCAwoQGlCA0IAChAYUaBWa7c22X7N9xPZdfQ8FjI0nvcPa9oyk1yVdL2lW0h5JtyY5tMD38FpHrEhLea3jlZKOJDma5KSkRyTd1OVwwNi1CW2NpGOnfT3bXPYptrfa3mt7b1fDAWPR2dtkkuyQtEPi1BH4rDZHtOOS1p329drmMgAttQltj6TLba+3fb6kWyQ90e9YwLhMPHVM8rHt2yU9I2lG0v1JDvY+GTAiE5/eP6cb5TEaVihWGQADIjSgAKEBBQgNKEBoQAFCAwoQGlCgl5Xglcb8QYr2WX8l04vKn2Pl/ZoWHNGAAoQGFCA0oAChAQUIDShAaEABQgMKEBpQgNCAAoQGFJgYmu37bZ+w/UrFQMAYtTmi/VbS5p7nAEZtYmhJnpf0bsEswGh19up921slbe3q9oAxabVuzvZlkp5M8s1WN1q4bo63yXSDt8l0g3VzwIAIDSjQ5un9hyX9RdIG27O2f9L/WMC4LPuV4DxG6waP0brBYzRgQIQGFCA0oAChAQUIDShAaEABQgMKLPuV4Fh+qn/3OQ2/t+OIBhQgNKAAoQEFCA0oQGhAAUIDChAaUIDQgAKEBhQgNKBAm50h62w/Z/uQ7YO2t1cMBozJxJ0htldLWp1kv+2LJe2TdHOSQwt8DztDOjDWnSHVin+O57YzJMmbSfY3f/5A0mFJa7odDxi3Rb16v9lYvFHSi2f5O1aCA/NovW7O9kWS/iTpl0kem3BdTh07wKljN5bFqaMk2T5P0qOSdk2KDMCZ2jwZYkkPSno3yR2tbpQjWic4onVjGo5obUL7tqQXJL0s6ZPm4ruTPLXA9xBaBwitG8sitHNBaN0gtG5MQ2i8MgQoQGhAAUIDChAaUIDQgAKEBhQgNKAAoQEFlv3u/WnYqz4G/Bz7xRENKEBoQAFCAwoQGlCA0IAChAYUIDSgAKEBBQgNKNBmJfjnbf/N9t+bleC/qBgMGJO2W7AuTPJhs3buz5K2J/nrAt8z3gUUwALm2xky8bWOmSvxw+bL85p/CAlYhLYLVGdsH5B0QtKzSc66Etz2Xtt7O54RWPYWtW7O9qWSHpe0LckrC1yPIx5WpE7WzSV5T9JzkjZ3MBOwYrR51vHLzZFMtr8g6XpJr/Y8FzAqbd74uVrSg7ZnNBfm75M82e9YwLgs+5XgwDRhJTgwIEIDChAaUIDQgAKEBhQgNKAAoQEFCA0osOxXgvPZy93g59gvjmhAAUIDChAaUIDQgAKEBhQgNKAAoQEFCA0oQGhAAUIDCrQOrVmi+pJtFvMAi7SYI9p2SYf7GgQYs7YrwddKukHSzn7HAcap7RHtXkl3Svpkviuwex+YX5tNxVsknUiyb6HrJdmRZFOSTZ1NB4xEmyPa1ZJutP2GpEckXWv7oV6nAkZmsZ8m8x1JP0uyZcL1yt5FyBsWu8HPsRtsKgYGtOx37/Nf4m7wc+wGRzRgQIQGFCA0oAChAQUIDShAaEABQgMKEBpQgNCAAoQGFCA0oAChAQUIDShAaEABQgMKEBpQgNCAAoQGFFjV5krNBqwPJP1P0seslAMWp1Voje8meae3SYAR49QRKNA2tEj6g+19tree7QqsBAfm12rdnO01SY7b/oqkZyVtS/L8Atdn3VwHWDfXjWWzbi7J8eZ/T0h6XNKV3Y0GjF+bD7m40PbFp/4s6XuSXul7MGBM2jzr+FVJjzeH31WSfpfk6V6nAkaGleBTjMdo3Vg2j9EALA2hAQUIDShAaEABQgMKEBpQgNCAAot5m8xU8j2FvyO5Z7y/a6p0T+HvtaYFRzSgAKEBBQgNKEBoQAFCAwoQGlCA0IAChAYUIDSgAKEBBVqFZvtS27ttv2r7sO2r+h4MGJO2r3X8taSnk/zA9vmSLuhxJmB0JoZm+xJJ10j6sSQlOSnpZL9jAePS5tRxvaS3JT1g+yXbO5v9jp/CSnBgfm1CWyXpCkn3Jdko6SNJd332Skl2JNnERzoBZ2oT2qyk2SQvNl/v1lx4AFqaGFqStyQds72hueg6SYd6nQoYmbbPOm6TtKt5xvGopNv6GwkYn1ahJTkgicdewDnilSFAAUIDChAaUIDQgAKEBhQgNKAAoQEFCA0osOw/wxqYJnyGNTAgQgMKEBpQgNCAAoQGFCA0oAChAQUIDShAaECBiaHZ3mD7wGn/vG/7joLZgNFY1EuwbM9IOi7pW0n+ucD1eAkWVqSuXoJ1naR/LBQZgDO1XTd3yi2SHj7bX9jeKmnrkicCRqj1qWOz0/Hfkr6R5D8TrsupI1akLk4dvy9p/6TIAJxpMaHdqnlOGwEsrNWpY/MxTf+S9PUk/21xfU4dsSLNd+rIO6yBDvEOa2BAhAYUIDSgAKEBBQgNKEBoQAFCAwoQGlBgsa/eb+sdSYt9K82Xmu8bo7HeN+7Xp31tvr/o5ZUh58L23iSj/ED6sd437ld7nDoCBQgNKDBNoe0YeoAejfW+cb9amprHaMCYTdMRDRgtQgMKTEVotjfbfs32Edt3DT1PF2yvs/2c7UO2D9rePvRMXbI9Y/sl208OPUuXbF9qe7ftV20ftn1VJ7c79GO0Zinr65KulzQraY+kW5McGnSwJbK9WtLqJPttXyxpn6Sbl/v9OsX2TyVtkvTFJFuGnqcrth+U9EKSnc3mtwuSvLfU252GI9qVko4kOZrkpKRHJN008ExLluTNJPubP38g6bCkNcNO1Q3bayXdIGnn0LN0yfYlkq6R9BtJSnKyi8ik6QhtjaRjp309q5H8H/IU25dJ2ijpxYFH6cq9ku6U9MnAc3RtvaS3JT3QnBbvbBZTLdk0hDZqti+S9KikO5K8P/Q8S2V7i6QTSfYNPUsPVkm6QtJ9STZK+khSJ88ZTENoxyWtO+3rtc1ly57t8zQX2a4kjw09T0eulnSj7Tc0d5p/re2Hhh2pM7OSZpOcOvPYrbnwlmwaQtsj6XLb65sHn7dIemLgmZbMtjV3rn84ya+GnqcrSX6eZG2SyzT37+qPSX448FidSPKWpGO2NzQXXSepkyev+nqbTGtJPrZ9u6RnJM1Iuj/JwYHH6sLVkn4k6WXbB5rL7k7y1HAjoYVtknY1/9E/Kum2Lm508Kf3gZVgGk4dgdEjNKAAoQEFCA0oQGhAAUIDChAaUOD/1n/hMITEaHcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_map = [\n",
    "    [WALL, WALL, WALL, WALL, WALL, WALL, WALL],\n",
    "    [WALL, EMPTY, AGENT1, WALL, EMPTY, AGENT2, WALL],\n",
    "    [WALL, EMPTY, EMPTY, WALL, EMPTY, EMPTY, WALL],\n",
    "    [WALL, WALL, WALL, WALL, WALL, WALL, WALL],\n",
    "    [WALL, EMPTY, EMPTY, WALL, EMPTY, EMPTY, WALL],\n",
    "    [WALL, EMPTY, EMPTY, WALL, EMPTY, EMPTY, WALL],\n",
    "    [WALL, TARGET1, EMPTY, WALL, EMPTY, TARGET2, WALL],\n",
    "    [WALL, WALL, WALL, WALL, WALL, WALL, WALL],\n",
    "]\n",
    "\n",
    "env = GridworldEnv(grid_map)\n",
    "state = env.reset()\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ab528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
